# VertiPaq Engine Reference Notes

A comprehensive reference on VertiPaq (the in-memory columnar engine powering Power BI, Azure Analysis Services, and SQL Server Analysis Services Tabular) with a focus on how DAX code patterns translate to engine behavior and why certain patterns are faster than others.

---

## 1. Architecture Overview: Two Engines

The Analysis Services Tabular engine processes every DAX query through two cooperating engines:

### Storage Engine (SE)

- **Role**: Retrieves data from the VertiPaq in-memory store (or DirectQuery source).
- **Query language**: xmSQL — an internal SQL-like language generated by the formula engine.
- **Execution model**: Multithreaded. Can use all available cores to scan compressed column segments in parallel.
- **Operations supported**: Scan, filter (equality, range, IN list), group by, simple aggregations (SUM, COUNT, MIN, MAX, DISTINCTCOUNT), joins across relationships.
- **Performance characteristic**: Extremely fast. Operates on compressed data in memory using batch processing, SIMD instructions, and bitmap filtering.
- **Cache**: SE results are cached (datacache). Identical xmSQL queries hit the cache immediately. Cache is invalidated on model refresh.

### Formula Engine (FE)

- **Role**: Orchestrates query execution, handles all logic that the SE cannot perform, and assembles the final result.
- **Execution model**: Single-threaded. All FE operations run on one core.
- **Operations handled**: Complex expressions, iterators with context transitions, conditional logic (IF/SWITCH), custom aggregations (SUMX with multi-column expressions), table materialization, DAX functions with no SE equivalent.
- **Performance characteristic**: Slow relative to SE. Single-threaded execution means it becomes the bottleneck on complex queries. Every row-by-row operation (iteration, context transition) is an FE operation.
- **No cache**: FE computations are not cached between queries (though VARs cache within a single query evaluation).

### The Optimization Principle

**Push as much work as possible to the Storage Engine.** Every operation that stays in the SE benefits from multithreaded compressed-data scanning. Every operation that falls to the FE becomes single-threaded row-by-row processing. The difference is often 10x-1000x on large datasets.

**How to identify SE vs FE in profiling:**
- **DAX Studio Server Timings**: Shows SE queries (xmSQL), SE duration, FE duration, and total duration.
- **SE percentage**: Aim for >90% SE time in query execution. High FE percentage indicates optimization opportunities.
- **Number of SE queries**: Fewer SE queries generally means better performance. Many small SE queries suggest excessive context transitions or CallbackDataID usage.

---

## 2. Columnar Storage and Compression

### How VertiPaq Stores Data

VertiPaq uses **columnar storage**: each column is stored independently as a compressed array of values. This is fundamentally different from row-based storage (traditional RDBMS).

**Implications for query patterns:**

| Aspect | Columnar (VertiPaq) | Row-based (RDBMS) |
|--------|---------------------|---------------------|
| Read pattern | Reads only columns referenced in query | Reads entire rows |
| Compression | Excellent (similar values cluster in a column) | Poor (diverse data types per row) |
| Aggregation | Very fast (scan one column, skip others) | Slower (must access full rows) |
| Point lookups | Slower (must decompress and scan column) | Fast (index seek to row) |
| Memory efficiency | High (compressed columnar segments) | Lower (row-level storage) |

**Key insight**: DAX expressions that reference fewer columns generate SE queries that scan fewer column segments. A measure like `SUM(Sales[Amount])` only touches one column. A measure like `SUMX(Sales, Sales[Quantity] * Sales[UnitPrice])` must read two columns and compute the product row by row.

### Dictionary Encoding

Every column is dictionary-encoded:

1. **Dictionary**: A sorted list of all distinct values in the column. Each unique value is assigned an integer ID.
2. **Data array**: The column data is stored as an array of dictionary IDs (not the actual values).

**Compression implications:**
- Low-cardinality columns (few unique values) compress extremely well. A column with 5 distinct values needs only 3 bits per row.
- High-cardinality columns (many unique values) compress poorly. A column with 10 million unique values may need 24+ bits per row.
- Column ordering within the table can affect compression: columns with lower cardinality should appear earlier (VertiPaq sorts by the first column, then by the second, etc., to maximize run-length encoding opportunities).

**Performance implications:**
- Filtering on low-cardinality columns is very fast (bitmap index on small dictionary).
- DISTINCTCOUNT on low-cardinality columns is nearly instant (just count dictionary entries matching the filter).
- DISTINCTCOUNT on high-cardinality columns is expensive (must scan the data array and build a unique-value bitmap).
- Calculated columns that produce high-cardinality results (e.g., concatenated keys, formatted strings) increase model size and reduce compression.

### Segments

Columns are divided into **segments** of approximately 8 million rows each (the exact size depends on the data). Each segment is independently compressed and can be scanned independently.

**Implications:**
- Parallel SE scanning operates at the segment level: different cores scan different segments simultaneously.
- Very small tables (under 8M rows) have only one segment per column, limiting parallelism for that table.
- Table partitioning in SSAS/Azure AS can create additional segments, improving refresh parallelism.

---

## 3. Materialization and Spooling

### What Is Materialization?

When the SE cannot answer a query directly (because it involves complex expressions, context transitions, or unsupported operations), the FE must create intermediate result sets. This process is called **materialization** (or **spooling** in some contexts).

**Materialization occurs when:**

1. **FILTER over a table**: `FILTER(Table, predicate)` materializes the filtered table as a rowset in FE memory. Each row is evaluated individually against the predicate.

2. **ADDCOLUMNS with measure evaluation**: `ADDCOLUMNS(table, "col", [Measure])` materializes the table and evaluates the measure for each row via context transition.

3. **Complex CALCULATE filter arguments**: When a filter argument is not a simple column predicate (e.g., involves OR across columns, function calls), the engine may materialize an intermediate table.

4. **CrossJoin operations**: Functions like CROSSJOIN, GENERATE, and nested iterators with multiple table scans can produce large materialized tables.

### Cost of Materialization

- Materialized tables are held in FE memory (single-threaded, uncompressed).
- Memory consumption can spike dramatically: a table with 10M rows materialized in the FE uses far more memory than the same table compressed in VertiPaq.
- FE processes materialized rows one at a time: no SIMD, no batch processing, no multi-core parallelism.
- In DAX Studio, materialization appears as large "datacache" entries in the SE queries tab. The number of rows in the datacache indicates the materialization size.

### How to Avoid Materialization

1. **Use direct column predicates** in CALCULATE instead of FILTER.
2. **Reduce iterator granularity**: iterate over smaller tables (VALUES of a key column instead of the full fact table).
3. **Avoid ADDCOLUMNS on large tables**: if you must add calculated columns to a table, do it on an already-grouped result (small table), not on the raw fact table.
4. **Use SUMMARIZECOLUMNS** instead of ADDCOLUMNS + SUMMARIZE.
5. **Push complex predicates to calculated columns** (computed at refresh time) so that the SE can filter on them directly.

---

## 4. How CALCULATE Translates to Engine Operations

CALCULATE is the most important DAX function. Understanding how it translates to engine operations is essential for optimization.

### CALCULATE Without Filter Arguments (Context Transition)

When CALCULATE is invoked in a row context (inside an iterator or a calculated column) without filter arguments:

1. The FE takes the current row context (all column values of the current row).
2. It creates a new filter context by adding a filter for each column in the table.
3. The expression inside CALCULATE is evaluated in this new filter context.
4. The SE receives a query filtered by all column values of the current row.

**Performance cost**: One SE query per unique combination of column values in the iterated table. If the table has 1M rows with 500K unique combinations across the referenced columns, up to 500K SE queries may be generated (SE cache deduplicates identical queries).

### CALCULATE With Simple Column Predicates

```dax
CALCULATE ( SUM ( Sales[Amount] ), Products[Category] = "Electronics" )
```

Translation:
1. The FE adds `Products[Category] = "Electronics"` to the current filter context (overwriting any existing filter on `Products[Category]`).
2. A single xmSQL query is sent to the SE: `SELECT SUM(Sales[Amount]) FROM Sales WHERE Products[Category] = 'Electronics'` (simplified).
3. The SE scans the Sales[Amount] column, applying the filter through the relationship to Products[Category] using bitmap filtering.

**Performance cost**: Minimal. One SE query, evaluated in parallel across column segments.

### CALCULATE With FILTER(ALL(...))

```dax
CALCULATE ( SUM ( Sales[Amount] ), FILTER ( ALL ( Products ), Products[Category] = "Electronics" ) )
```

Translation:
1. The FE evaluates `ALL(Products)` — requests all rows of Products ignoring current filter context.
2. The SE returns the entire Products table (materialized in FE memory).
3. The FE iterates row by row through Products, applying `Products[Category] = "Electronics"`.
4. The resulting filtered table is used as the filter argument for CALCULATE.
5. A new SE query is sent for the SUM with the filter applied.

**Performance cost**: Much higher than the direct predicate version. The materialization of the Products table is an extra SE query + FE iteration. For small dimension tables (1000 rows), the overhead is small. For large tables, it is significant.

### CALCULATE With KEEPFILTERS

```dax
CALCULATE ( SUM ( Sales[Amount] ), KEEPFILTERS ( Products[Category] = "Electronics" ) )
```

Translation:
1. The FE creates a filter for `Products[Category] = "Electronics"`.
2. Instead of overwriting the existing filter on `Products[Category]`, it intersects (ANDs) the new filter with the existing one.
3. The SE receives a combined filter predicate.

**Performance cost**: Same as direct predicate. No additional materialization. The only difference is in the filter merging logic (intersection vs overwrite).

---

## 5. CallbackDataID — The Performance Killer

### What Is CallbackDataID?

CallbackDataID is a mechanism where the SE cannot fully evaluate a query on its own and must "call back" to the FE for each row. It appears in SE queries (visible in DAX Studio) as a function call to `CallbackDataID(...)`.

### When Does It Occur?

CallbackDataID appears when:

1. **Measure references inside iterators**: `SUMX(Table, [Measure])` — the measure contains CALCULATE (context transition), and the SE cannot evaluate the measure's logic. The SE scans the table but calls back to the FE for each row to evaluate the measure.

2. **Complex expressions in FILTER**: `FILTER(Table, complexExpression)` where the expression involves multiple tables, measures, or functions the SE cannot handle.

3. **IF/SWITCH inside SE queries**: When conditional logic cannot be pushed entirely to the SE, a CallbackDataID is used for the conditional evaluation.

4. **CALCULATE with non-trivial filter expressions**: Filters involving functions or cross-table logic.

### Performance Impact

CallbackDataID has severe performance consequences:

- **Breaks multithreading**: Even though the SE scan is multithreaded, each row must pause to call back to the single-threaded FE for the callback evaluation.
- **Breaks batch processing**: Instead of processing compressed segments in bulk, the engine processes individual rows.
- **No caching of callbacks**: Each callback is evaluated independently (though the SE does cache SE-level results for identical row values).
- **Scales linearly with row count**: For N rows, there are N callbacks. Doubling the table size doubles the callback overhead.

### How to Eliminate CallbackDataID

1. **Avoid measure calls inside iterators over large tables.** Pre-aggregate to a smaller granularity first.
2. **Simplify FILTER predicates** to single-column comparisons that the SE can evaluate natively.
3. **Use VAR to pre-compute** values outside the iterator, avoiding the need for callbacks inside the iterator.
4. **Replace CALCULATE inside SUMX** with explicit column arithmetic when possible:
   ```dax
   // Generates CallbackDataID
   SUMX ( Sales, [Margin %] * Sales[Revenue] )

   // No CallbackDataID — pure SE operation
   SUMX ( Sales, ( Sales[Revenue] - Sales[Cost] ) / Sales[Revenue] * Sales[Revenue] )

   // Better yet, simplify the math
   SUM ( Sales[Revenue] ) - SUM ( Sales[Cost] )
   ```

---

## 6. Cardinality Impact on Performance

Cardinality (the number of distinct values in a column or the number of rows in a table) is the primary driver of query performance in VertiPaq.

### Column Cardinality

| Cardinality | Effect on Compression | Effect on Filtering | Effect on DISTINCTCOUNT |
|-------------|----------------------|---------------------|------------------------|
| Very low (2-10) | Excellent (1-4 bits/row) | Instant (bitmap) | Instant (dictionary) |
| Low (10-1000) | Good (10-12 bits/row) | Very fast | Very fast |
| Medium (1K-100K) | Moderate | Fast | Fast |
| High (100K-10M) | Poor (17-24 bits/row) | Moderate | Slow |
| Very high (>10M) | Very poor | Slow | Very slow |

### Table Row Count

| Row Count | SE Scan Time | Materialization Risk | Iterator Risk |
|-----------|-------------|---------------------|---------------|
| < 100K | Negligible | None | None |
| 100K - 1M | Low | Low | Low |
| 1M - 10M | Moderate | Medium | Medium |
| 10M - 100M | High | High | High (avoid iterators) |
| > 100M | Very high | Critical (avoid) | Critical (avoid) |

### Cardinality Rules of Thumb

1. **Group-by cardinality**: The number of distinct groups in a SUMMARIZECOLUMNS or visual determines the size of the result set. Keep it under 1M for interactive reports.
2. **Filter cardinality**: Filtering on a column with 10 distinct values is ~100x faster than filtering on a column with 1M distinct values.
3. **Relationship cardinality**: One-to-many relationships are efficient (bitmap cross-filtering). Many-to-many relationships require special handling and can produce large intermediate results.
4. **Cross-join cardinality**: CROSSJOIN of two tables with N and M rows produces N * M rows. Even moderate tables can create billions of virtual rows.
5. **Iterator cardinality**: The number of rows the iterator processes determines FE workload. SUMX over 1M rows means 1M FE operations. Pre-aggregate to reduce this.

---

## 7. Compression and Memory Considerations

### Memory Budget

VertiPaq keeps the entire model in memory. Every column, every relationship bitmap, every calculated column, and every aggregate consumes memory.

**Memory consumption per column:**
```
Memory = (Row Count) * (Bits per Value / 8) + Dictionary Size + Hierarchy Size
```

Where:
- Bits per value depends on cardinality: `ceil(log2(cardinality))` bits minimum.
- Dictionary size depends on the data type and the number of unique values.
- Hierarchy size applies to columns used in relationships.

### Common Memory Wasters

1. **High-cardinality calculated columns**: Concatenated keys, formatted strings, GUID-like values. Each unique value adds a dictionary entry and increases bits per value.
2. **Unnecessary columns imported**: Columns never used in any measure or relationship still consume memory. Remove them in Power Query.
3. **High-precision numbers**: Decimal(15,10) uses more memory than Integer. Use the smallest data type that fits the data.
4. **Date/time columns with time component**: A date column with time precision to the second can have 86,400x more distinct values than a date-only column. Split into separate Date and Time columns.
5. **Redundant denormalized columns**: The same Category name stored in both the Products dimension and the Sales fact table. Keep it only in the dimension; use the relationship.

### Compression Best Practices

1. **Star schema**: Dimension tables with low-cardinality attributes, fact tables with numeric measures and foreign keys. This maximizes compression.
2. **Remove unnecessary columns** in Power Query before loading.
3. **Split date-time** into separate Date and Time columns.
4. **Reduce cardinality** where possible: round decimal values, truncate timestamps, group rare categories into "Other".
5. **Use Integer keys** for relationships instead of string keys.
6. **Avoid calculated columns** that produce high-cardinality results; use measures instead.

---

## 8. Batch Mode vs Row Mode Processing

### SE Batch Mode

The storage engine processes data in **batches** — compressed column segments are scanned in bulk using vectorized operations. This is the fast path.

**Batch mode is used when:**
- Simple aggregations: SUM, COUNT, MIN, MAX, DISTINCTCOUNT on a single column.
- Filter predicates are simple column comparisons (=, <>, >, <, >=, <=, IN).
- Group-by operations on columns.
- Joins through defined relationships.

### FE Row Mode

The formula engine processes data **row by row**. This is the slow path.

**Row mode is used when:**
- Iterators (SUMX, AVERAGEX, etc.) with complex per-row expressions.
- Context transitions (measure calls inside iterators).
- CallbackDataID scenarios.
- Complex conditional logic that cannot be pushed to SE.
- Cross-table predicates in FILTER.

### Hybrid Execution

Most DAX queries involve both engines:

1. The FE parses the DAX and generates a query plan.
2. The FE sends one or more xmSQL queries to the SE.
3. The SE returns result sets (datacaches).
4. The FE combines the datacaches, applies any remaining logic, and produces the final result.

**Optimization goal**: Maximize the work done in step 3 (SE batch mode) and minimize step 4 (FE row mode).

### Identifying Execution Mode

In DAX Studio Server Timings:
- **SE queries**: Each line is an xmSQL query executed by the SE. Look at the number of rows returned (datacache size).
- **SE time**: Total time spent in SE. This is the "fast" time.
- **FE time**: Total time minus SE time. This is the "slow" time.
- **CallbackDataID** in xmSQL: Indicates the SE is calling back to FE for individual rows — worst case hybrid execution.

**Healthy query profile:**
- 1-5 SE queries
- SE time: 80-99% of total
- FE time: 1-20% of total
- No CallbackDataID
- Datacache sizes are small (hundreds to thousands of rows, not millions)

**Unhealthy query profile:**
- 50+ SE queries (excessive context transitions)
- FE time: >50% of total
- CallbackDataID present
- Large datacache (millions of rows materialized)

---

## 9. Relationships and Cross-Filtering

### How Relationships Work in VertiPaq

Relationships in VertiPaq are implemented as **bitmap indexes** that map row IDs in one table to row IDs in another.

**One-to-many relationship (e.g., Products -> Sales):**
- For each row in the "one" side (Products), a bitmap indicates which rows in the "many" side (Sales) are related.
- Filtering Products first, then aggregating Sales, is a bitmap AND operation — extremely fast.
- Cross-filter direction determines which direction the filter propagates. Default: single direction (from one side to many side).

**Many-to-many relationship:**
- Requires an intermediate bridge table.
- Filter propagation involves two relationship traversals and a bitmap intersection.
- More expensive than one-to-many, especially with high cardinality on both sides.

### Bi-directional Cross-Filtering

Enabling bi-directional cross-filtering on a relationship allows filters to propagate in both directions. This is convenient but has performance and ambiguity implications:

- **Performance**: The engine must maintain and evaluate bitmaps in both directions, which can increase SE query complexity.
- **Ambiguity**: With multiple bi-directional relationships forming a cycle, the engine may produce unexpected filter propagation. Always break cycles with CROSSFILTER or USERELATIONSHIP in measures.
- **Recommendation**: Avoid bi-directional cross-filtering as a model default. Use CROSSFILTER() in specific measures where reverse filtering is needed.

### USERELATIONSHIP and CROSSFILTER

- `USERELATIONSHIP(column1, column2)`: Activates an inactive relationship for the scope of the CALCULATE. The SE uses the specified relationship's bitmap index instead of the active one.
- `CROSSFILTER(column1, column2, direction)`: Changes the cross-filter direction (None, OneWay, Both) for the scope of the CALCULATE.

Both functions modify the SE query plan and bitmap index usage. They do not add FE overhead beyond the initial context setup.

---

## 10. Query Plan Optimization Tips

### Writing SE-Friendly DAX

1. **Use simple aggregators** (SUM, COUNT, MIN, MAX, DISTINCTCOUNT) instead of iterators when possible.
2. **Use direct column predicates** in CALCULATE instead of FILTER.
3. **Keep CALCULATE filter arguments as simple column comparisons.** Avoid function calls, cross-table logic, or OR across different columns in a single filter argument.
4. **Minimize context transitions**: Avoid calling measures inside SUMX/AVERAGEX over large tables. Pre-aggregate to a smaller table first.
5. **Use VAR** to cache intermediate results. VARs are evaluated once and reused, reducing both SE queries and FE computation.
6. **Use SUMMARIZECOLUMNS** for calculated tables and report-level aggregation. It produces optimized SE queries.
7. **Avoid unnecessary CALCULATE nesting.** Each CALCULATE boundary adds filter context overhead.

### When FE Is Unavoidable

Some DAX patterns inherently require FE processing:

- **Dynamic conditional aggregation**: `SUMX(Table, IF(condition, colA, colB))` — the IF must be evaluated per row in the FE.
- **String operations**: CONCATENATEX, FORMAT inside iterators — string functions are FE-only.
- **Complex ranking**: RANKX with complex tie-breaking — requires FE iteration.
- **Custom aggregation logic**: Weighted averages, running totals, percentile calculations — often require iterators.

In these cases, the optimization strategy shifts to:
1. **Reduce the iterator's input size**: Group or filter the input table to the minimum necessary rows.
2. **Simplify the per-row expression**: Move any sub-aggregation to a VAR computed before the iterator.
3. **Avoid nested iterators**: Flatten the logic or pre-compute intermediate tables.

### Profiling and Diagnosis

Use these tools to diagnose performance:

1. **DAX Studio** — Connect to the Power BI model, execute queries, and view Server Timings (SE queries, FE time, datacache sizes, CallbackDataID).
2. **Performance Analyzer** (in Power BI Desktop) — Capture visual-level query execution times. Identify which visuals generate slow queries.
3. **VertiPaq Analyzer** — Analyze the model's memory footprint. Identify large tables, high-cardinality columns, and unused columns.
4. **Query Plan** (in DAX Studio) — View the logical and physical query plans. Identify SpoolLookup, CrossApply, and other FE-heavy operators.

**Red flags in query plans:**
- `SpoolLookup` — indicates table materialization (spooling).
- `CrossApply` — indicates nested iteration / context transition.
- `CallbackDataID` in xmSQL — indicates SE-to-FE callbacks per row.
- Large datacache row counts (>100K rows) — indicates excessive materialization.
- Many SE queries (>10 for a single measure) — indicates excessive context transitions.

---

## 11. DirectQuery and Composite Model Considerations

When the model uses DirectQuery or composite (mixed) storage mode, the engine behavior changes:

### DirectQuery Mode

- **No VertiPaq**: Data stays in the source database. Queries are translated to SQL (not xmSQL) and sent to the source.
- **No compression benefits**: Query performance depends on the source database's indexing and query optimizer.
- **No SE cache**: Every query hits the source. No benefit from datacache reuse.
- **Limited DAX function support**: Some DAX functions cannot be translated to SQL and fall back to FE materialization.
- **Recommendation**: Keep DAX as simple as possible. Avoid iterators, complex FILTER, and context transitions. Push complexity to the source (views, computed columns in the database).

### Composite Models (Dual / Mixed Storage)

- Tables can be VertiPaq (Import) or DirectQuery.
- Queries spanning both storage modes require **hybrid execution**: the engine fetches data from both sources and joins them in the FE.
- **Aggregation tables**: Pre-aggregated Import tables that the engine uses to answer queries at high granularity without hitting the DirectQuery source.
- **Recommendation**: Place frequently filtered/aggregated tables in Import mode. Use DirectQuery only for detail-level access or very large tables that do not fit in memory. Define aggregation tables to reduce DirectQuery calls.

---

## 12. Summary of Engine Behavior by DAX Function

| DAX Function | Engine | Notes |
|-------------|--------|-------|
| SUM, COUNT, MIN, MAX | SE | Direct aggregator — fastest path |
| DISTINCTCOUNT | SE | Uses dictionary; expensive on high cardinality |
| CALCULATE (column predicates) | SE | Filter becomes SE predicate |
| CALCULATE (FILTER(...)) | FE + SE | FILTER materializes in FE; inner aggregation in SE |
| SUMX, AVERAGEX, MINX, MAXX | FE (iterates) + SE (per-row or batch) | Simple column references may batch; complex expressions go row-mode |
| FILTER | FE | Always iterates row by row |
| ALL, ALLEXCEPT, REMOVEFILTERS | SE (filter modification) | Modifies the SE filter predicate |
| KEEPFILTERS | SE (filter modification) | Changes merge behavior; same SE cost |
| SUMMARIZECOLUMNS | SE (optimized) | Single SE query with group-by and aggregation |
| ADDCOLUMNS | FE (iterates) | Each row evaluated in FE; context transition if measure is used |
| SUMMARIZE (grouping only) | SE | Group-by is a SE operation |
| SUMMARIZE (with expressions) | FE + SE | Deprecated pattern; use SUMMARIZECOLUMNS |
| VALUES, DISTINCT | SE | Returns distinct values from SE dictionary |
| SELECTEDVALUE | SE | Sugar over HASONEVALUE + VALUES |
| SWITCH, IF | FE | Conditional logic is always FE |
| FORMAT, CONCATENATEX | FE | String operations are always FE |
| Time intelligence (DATEADD, etc.) | SE | Generates date range filter for SE |
| RANKX | FE | Requires full iteration and sorting in FE |
| TOPN | FE + SE | SE retrieves data; FE sorts and truncates |
| CROSSJOIN, GENERATE | FE | Creates Cartesian product in FE memory |
| TREATAS | SE | Creates virtual relationship filter for SE |
| USERELATIONSHIP | SE | Activates alternative SE relationship bitmap |
| CROSSFILTER | SE | Modifies SE cross-filter direction |
| LOOKUPVALUE | FE | Row-by-row lookup; consider RELATED + relationship instead |
| RELATED | SE | Follows relationship bitmap — fast |
| RELATEDTABLE | FE | Returns table; iterates in FE |
